# Domain 5: Epistemological Genre
## Level 1 Assessment - Knowledge Recognition

**Time**: 30-45 minutes
**Passing**: ≥80% (10/12 questions)
**Retake**: Immediate, unlimited

---

## Section A: Multiple Choice (10 questions)

### Question 1
A researcher conducts 50 interviews to understand how surgical trainees learn. Their analysis reveals shadow learning as a mechanism. Which genre best describes this work?

- a) Hypothesis testing
- b) Theory building (discovery)
- c) Theory testing (confirmation)
- d) Descriptive case study

**Correct**: b
**Why**: The researcher used qualitative data to discover a mechanism that wasn't known before. This is theory building—generating new theoretical insight from empirical observation. Testing would require starting with a hypothesis.

---

### Question 2
A reviewer criticizes a qualitative paper for "lack of generalizability across a representative sample." What's wrong with this critique?

- a) Nothing—generalizability always matters
- b) It applies hypothesis-testing standards to theory-building work—qualitative discovery doesn't require representative samples
- c) The sample is probably large enough
- d) Qualitative work should still have large samples

**Correct**: b
**Why**: Theory-building work aims for theoretical generalization (the mechanism applies in principle), not statistical generalization (the proportion in a population). You don't need a representative sample to discover a mechanism.

---

### Question 3
What distinguishes "discovery" research from "testing" research?

- a) Discovery uses qualitative data; testing uses quantitative
- b) Discovery generates new theory from data; testing evaluates existing theory against data
- c) Discovery is easier; testing is more rigorous
- d) Discovery comes first; testing comes second

**Correct**: b
**Why**: The key distinction is the relationship between theory and data. Discovery: data → theory (inductive). Testing: theory → data (deductive). Both can use qualitative or quantitative methods.

---

### Question 4
A researcher writes: "We hypothesize that shadow learning improves skill acquisition" before collecting data. They then interview 20 successful learners and find shadow learning present in all of them. What's the epistemological problem?

- a) Sample is too small
- b) They're mixing genres—claiming to test a hypothesis but using discovery methods that can't falsify it
- c) Interviews are unreliable
- d) The hypothesis is too obvious

**Correct**: b
**Why**: Hypothesis testing requires the possibility of disconfirmation. Interviewing only successful learners can't falsify the hypothesis—you'd need to compare with unsuccessful learners and show shadow learning distinguishes them.

---

### Question 5
A researcher discovers a mechanism through qualitative coding. In the Discussion section, they write: "We have proven that shadow learning causes skill acquisition." Which genre violation is this?

- a) Overclaiming causation from qualitative discovery work—discovery establishes plausibility, not proof
- b) Being too confident
- c) Missing citations
- d) Wrong section placement

**Correct**: a
**Why**: Discovery work establishes that a mechanism is plausible and operating. "Proof" and "causes" require testing designs that can rule out alternatives. Qualitative discovery shows something IS happening; it can't prove the causal claim.

---

### Question 6
Which claim is appropriate for theory-building qualitative research?

- a) "We prove that X causes Y"
- b) "We test the hypothesis that X leads to Y"
- c) "We identify a mechanism by which X appears to enable Y, generating theory for future testing"
- d) "We verify that X is the primary cause of Y"

**Correct**: c
**Why**: Theory-building claims should acknowledge that you've discovered something that appears to operate, while leaving space for future testing. "Identify," "appears to," and "generating theory for future testing" are appropriate hedges.

---

### Question 7
A paper uses qualitative discovery methods but makes hypothesis-testing claims. A reviewer says the paper has "genre confusion." What should the author do?

- a) Add quantitative data
- b) Align claims with methods—either make discovery claims or redesign the study for testing
- c) Remove all theoretical language
- d) Cite more hypothesis-testing papers

**Correct**: b
**Why**: Genre confusion means the claims don't match the methods. Fix by either: (1) rewriting claims to be appropriate for discovery ("we identify," "we theorize"), or (2) redesigning the study to actually test hypotheses (comparison groups, falsification logic).

---

### Question 8
A researcher wants to test whether shadow learning improves skill. Which design would allow a testing claim?

- a) Interview successful learners and ask if they did shadow learning
- b) Compare skill outcomes between learners who did/didn't engage in shadow learning, controlling for confounds
- c) Code interviews for shadow learning themes
- d) Survey trainees about their learning practices

**Correct**: b
**Why**: Testing requires comparison and the possibility of falsification. Comparing outcomes between groups who did/didn't engage in the practice—while controlling for alternatives—is a testing design that could disconfirm the hypothesis.

---

### Question 9
A qualitative researcher argues that "thick description" of a single case can be as valuable as testing across many cases. When is this true?

- a) Never—single cases can't generalize
- b) When the goal is discovery (generating theory) rather than testing (confirming theory)
- c) Only for exploratory studies
- d) Only for descriptive studies

**Correct**: b
**Why**: Single cases are excellent for discovery—revealing mechanisms that weren't previously understood. They're poor for testing because they can't assess prevalence or rule out alternatives. The value depends on the epistemological goal.

---

### Question 10
A researcher conducted a qualitative study discovering a mechanism. They now want to write a follow-up paper testing the mechanism quantitatively. What should they be careful about?

- a) Using the same site would be problematic
- b) Their discovery sample shouldn't also be their testing sample—that's fitting theory to the same data twice
- c) Quantitative methods are less rigorous
- d) They should stick to qualitative methods

**Correct**: b
**Why**: If you discover a pattern in data and then "test" it on the same data, you've just redescribed your discovery. Genuine testing requires new data that could disconfirm the theory. Discovery sample ≠ testing sample.

---

### Question 11 (Front-Loading)
A researcher opens their abstract with: "When genuinely novel technology arrives, managers cannot evaluate skill fit because the relevant performance criteria do not yet exist."

This is a discovery paper. What's wrong with this opening?

- a) It's too long
- b) It front-loads discoveries as premises—"managers decide," "skill fit evaluation," and "criteria don't exist" are all things the paper discovers, not accepted starting points
- c) It needs more citations
- d) It should start with a hypothesis

**Correct**: b
**Why**: Discovery papers must start from the naive question a reader would ask ("What happens to workers when automation arrives?"). The example presents discovered mechanism components as if they're accepted premises. A naive reader wouldn't know managers are the key actors, that skill evaluation matters, or that criteria absence is the issue—those are findings.

---

### Question 12 (Front-Loading)
Which abstract opening is appropriate for a discovery paper about how organizations select workers for new technology?

- a) "Selection into automation roles operates through reliability hedging, a mechanism we identify..."
- b) "Organizations face a fundamental challenge when deploying novel technology: they cannot evaluate worker fit because performance criteria don't yet exist."
- c) "What happens to workers when automation arrives? Job insecurity theory predicts displacement. Yet at one facility, tenure quadrupled..."
- d) "We theorize that managers select workers based on reliability rather than skill when facing technological uncertainty."

**Correct**: c
**Why**: Option (c) starts from the naive question, presents the theoretical expectation, then introduces the puzzle. Options (a), (b), and (d) all front-load discoveries—they present what the paper found as if it's the starting point rather than the destination.

---

## Section B: Short Answer (2 questions)

### Question 13
A researcher writes: "Through interviews with 30 surgical trainees, we tested our hypothesis that shadow learning improves skill acquisition. All 30 trainees who engaged in shadow learning reported feeling more competent."

Identify at least TWO epistemological problems with this claim.

**Model answer should include any 2 of**:
- Mixed genre: Claims to "test hypothesis" but used discovery methods (interviews, no comparison group)
- No falsification possible: Interviewing only trainees who did shadow learning can't test whether it works—no comparison to those who didn't
- Self-report bias: "Feeling more competent" isn't skill acquisition—measuring perceptions, not outcomes
- Selection problem: Trainees who engaged in shadow learning may differ in other ways (motivation, talent)
- Appropriate claim: "We found that trainees who engaged in shadow learning reported feeling more competent, suggesting a mechanism worth testing"

---

### Question 14
Explain the difference between "theoretical generalization" and "statistical generalization." Which type does qualitative discovery research aim for, and why doesn't it require a representative sample?

**Model answer should include**:
- Statistical generalization: Inferring from sample to population (requires representative sampling)
- Theoretical generalization: Inferring from case to mechanism (requires revealing how something works)
- Qualitative discovery aims for theoretical generalization—showing that a mechanism operates and under what conditions
- Representative sampling isn't needed because the goal is to understand the mechanism, not to estimate its prevalence
- Example: You don't need 1000 hospitals to discover how shadow learning works; you need deep access to cases where it operates
- The logic is: "If I can show this mechanism operates here, it may operate anywhere these conditions hold"

---

## Answer Key

| Question | Answer |
|----------|--------|
| 1 | b |
| 2 | b |
| 3 | b |
| 4 | b |
| 5 | a |
| 6 | c |
| 7 | b |
| 8 | b |
| 9 | b |
| 10 | b |
| 11 | b |
| 12 | c |
| 13 | See model answer |
| 14 | See model answer |

**Scoring**:
- MC: 1 point each (12 points)
- Short answer: 2 points each (4 points)
- Total: 16 points
- Pass: ≥13 points (80%)
