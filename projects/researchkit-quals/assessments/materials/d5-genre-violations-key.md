# D5 Genre Violations Draft: Answer Key

## Overview

**Source**: `d5-genre-violations-draft.md`
**Target Domain**: Domain 5 (Epistemological Genre), Levels 2 and 3
**Total violations seeded**: 12 (3 structural, 5 language, 3 temporal logic, 1 hybrid)

The paper presents a competent ethnographic study of AI tools in consulting firms. The fieldwork is solid, the observations are interesting, and the quotes feel real. The problem is entirely in the framing: the researcher conducted inductive, discovery-oriented fieldwork but wrote it up using deductive, hypothesis-testing conventions. This is exactly the kind of genre violation that reviewers at Organization Science would flag immediately.

---

## Structural Violations

### SV-1: "Hypothesis Development" section header
- **Location**: Section header "Theoretical Background and Hypothesis Development"
- **Exact text**: `## Theoretical Background and Hypothesis Development`
- **Type**: Structural
- **Why it's a violation**: This section header signals deductive, theory-testing research. In a discovery paper, this section should be "Theoretical Background" or "Sensitizing Concepts." The researcher didn't enter the field with hypotheses to test --- they discovered patterns and are retrofitting a deductive frame.
- **Genre-appropriate alternative**: "Theoretical Background" or "Sensitizing Concepts and Prior Literature"
- **Difficulty**: Easy. This is one of the most recognizable red flags and is explicitly called out in the competency materials.

### SV-2: Numbered hypotheses (H1, H2, H3)
- **Location**: End of each subsection in Theoretical Background
- **Exact text**: `**H1**: AI tool adoption will lead consultants to shift...`, `**H2**: AI tool adoption will shift the locus of analytical expertise...`, `**H3**: AI tool adoption will create a new axis of status differentiation...`
- **Type**: Structural
- **Why it's a violation**: Numbered hypotheses are the hallmark of deductive research. The researcher spent 14 months doing ethnographic fieldwork --- they didn't derive H1, H2, H3 from theory before entering the field. These "hypotheses" are discovered patterns dressed up in testing language. Organization Science reviewers would see this immediately.
- **Genre-appropriate alternative**: Frame as research questions or sensitizing themes. E.g., "Prior research suggested that technology adoption might reshape client interactions, but how this plays out in AI-augmented consulting remained unclear" --- then let the findings section reveal what was discovered.
- **Difficulty**: Easy. Numbered hypotheses in an ethnographic paper is the textbook example of genre mismatch.

### SV-3: "Results" section structured as hypothesis confirmation
- **Location**: The entire Results section
- **Exact text**: Section headers `### H1: Shift from Exploratory to Hypothesis-Driven Client Interactions`, `### H2: Migration of Expertise to Human-AI Assemblages`, `### H3: AI Fluency as Status Differentiator`
- **Type**: Structural
- **Why it's a violation**: The Results section is organized around confirming/disconfirming each hypothesis, which is appropriate for testing papers but not for discovery papers. A discovery paper should present "Findings" organized around emergent themes, with the data leading the narrative. Organizing findings by hypothesis number makes the paper read like a confirmation exercise rather than a discovery narrative.
- **Genre-appropriate alternative**: "Findings" section organized around emergent themes, e.g., "Reconfigured Preparation Practices," "The Emergence of Human-AI Assemblages," "New Status Dynamics." Let the data tell the story; connect to theory in the Discussion.
- **Difficulty**: Medium. Students may recognize the H1/H2/H3 labeling as wrong but miss that the entire organizational structure of the findings is genre-inappropriate.

### SV-4 (Borderline): Variables-and-relationships framing in future directions
- **Location**: Last paragraph of Discussion
- **Exact text**: `Future research should examine whether the variables and relationships we identified hold in other knowledge-intensive contexts`
- **Type**: Structural / Language hybrid
- **Why it's a violation**: "Variables and relationships" is the language of deductive, quantitative research. Ethnographic research identifies processes, patterns, and mechanisms --- not "variables." This framing reduces the richness of processual findings to a variables-and-relationships model.
- **Genre-appropriate alternative**: "Future research should examine whether the patterns and processes we observed unfold similarly in other knowledge-intensive contexts"
- **Difficulty**: Hard. This is a subtle framing issue in a single sentence. Students trained in quantitative methods might not even register "variables and relationships" as problematic.

---

## Language Violations

### LV-1: "Consistent with our prediction"
- **Location**: First paragraph of H1 Results subsection
- **Exact text**: `Consistent with our prediction, we found that AI tool adoption led consultants to shift from open-ended, exploratory client interactions to more targeted, hypothesis-driven conversations.`
- **Type**: Language
- **Why it's a violation**: "Consistent with our prediction" implies the researcher predicted this outcome before seeing the data. In a 14-month ethnography, the researcher discovered this pattern --- they didn't predict it. This phrase is classic HARKing (Hypothesizing After Results are Known) language.
- **Genre-appropriate alternative**: "I observed that AI tool adoption led consultants to shift..." or "A striking pattern emerged: consultants shifted from open-ended, exploratory client interactions to more targeted conversations."
- **Difficulty**: Easy. This phrase is explicitly called out in the competency materials as a red flag.

### LV-2: "As hypothesized"
- **Location**: H3 Results subsection, second paragraph
- **Exact text**: `As hypothesized, AI fluency emerged as a new axis of status differentiation across all three firms.`
- **Type**: Language
- **Why it's a violation**: Same as LV-1. "As hypothesized" claims the researcher predicted this finding before seeing data. In an ethnography, status dynamics emerge from observation, not from hypotheses.
- **Genre-appropriate alternative**: "Across all three firms, I observed AI fluency emerging as a new axis of status differentiation" or "A pattern I had not anticipated became clear across all three sites: AI fluency was becoming a status marker."
- **Difficulty**: Easy. Explicit red flag phrase from the competency materials.

### LV-3: "We tested whether"
- **Location**: H2 Results subsection, third paragraph
- **Exact text**: `We tested whether this assemblage pattern held for more complex, judgment-intensive tasks.`
- **Type**: Language
- **Why it's a violation**: "Tested" implies a formal hypothesis test --- the deductive mode of inquiry. In ethnographic research, you examine, explore, or investigate whether patterns hold across contexts. "Tested" reduces qualitative inquiry to a binary confirmation exercise.
- **Genre-appropriate alternative**: "I examined whether this assemblage pattern extended to more complex, judgment-intensive tasks" or "I was curious whether this pattern held for tasks requiring deeper judgment."
- **Difficulty**: Medium. "Tested" is less obviously a red flag than "as hypothesized," and some students may see it as acceptable casual language.

### LV-4: "Results confirm"
- **Location**: H2 Results subsection, first paragraph
- **Exact text**: `Results confirm the predicted migration of analytical expertise from individual consultants to human-AI assemblages.`
- **Type**: Language
- **Why it's a violation**: "Results confirm the predicted" combines two violations: "confirm" implies verification of a prior prediction, and "predicted" claims the finding was anticipated. Discovery research doesn't confirm predictions --- it reveals patterns.
- **Genre-appropriate alternative**: "I observed a consistent migration of analytical expertise from individual consultants to what I came to call human-AI assemblages."
- **Difficulty**: Easy. Both "confirm" and "predicted" are red flag words.

### LV-5: "Support for H1 was found"
- **Location**: Last paragraph of H1 Results subsection
- **Exact text**: `Support for H1 was found across all three firms, though the magnitude varied.`
- **Type**: Language
- **Why it's a violation**: This is textbook hypothesis-testing language. "Support for H1" treats the finding as evidence for or against a pre-specified prediction. In a discovery paper, you would describe the pattern and note where it was more or less pronounced.
- **Genre-appropriate alternative**: "This shift in client interaction practices was evident across all three firms, though its intensity varied with the depth of AI tool adoption."
- **Difficulty**: Easy. Direct hypothesis-testing language.

---

## Temporal Logic Violations

### TL-1: Theory section derives "predictions" from theory the researcher found AFTER fieldwork
- **Location**: Subsections under "Hypothesis Development" --- particularly "AI Tools and Client Interaction Practices" and "AI Tools and the Locus of Expertise"
- **Exact text**: `Based on organizational learning theory, we predict that AI adoption will restructure client interaction practices.` and `We predict that this shift will manifest as a redistribution of analytical tasks...`
- **Type**: Temporal logic
- **Why it's a violation**: The theory section reads as if the researcher derived predictions from organizational learning theory BEFORE entering the field and then went to see if they held. In reality, a 14-month ethnographer almost certainly discovered the patterns first and then found theories that helped explain them. The temporal presentation --- theory first, prediction, then "test" --- reverses the actual epistemic order.
- **Genre-appropriate alternative**: Present organizational learning theory as a sensitizing framework that helped make sense of observed patterns. E.g., "Organizational learning theory (Argote & Miron-Spektor, 2011), with its emphasis on knowledge repositories, provided a useful lens for understanding the shifts I observed. But this framework only became central to my analysis midway through fieldwork, when the migration of expertise from individuals to human-AI configurations became too pronounced to ignore."
- **Difficulty**: Medium. Requires understanding temporal logic as a concept, not just spotting red flag words. The student needs to reason about what the researcher likely knew when.

### TL-2: Presenting discovered patterns as predicted a priori
- **Location**: Discussion section, first paragraph
- **Exact text**: `As predicted by organizational learning theory, AI tool adoption restructured consulting work in systematic ways`
- **Type**: Temporal logic
- **Why it's a violation**: "As predicted by" presents the findings as if organizational learning theory generated a priori predictions that the data then confirmed. This reverses the actual epistemic process: the researcher observed the patterns and then used organizational learning theory to make sense of them. Presenting discovery as prediction is a form of HARKing.
- **Genre-appropriate alternative**: "Organizational learning theory helps make sense of these findings: the migration of expertise to human-AI assemblages represents a novel form of the knowledge-repository dynamics that Argote and Miron-Spektor (2011) describe."
- **Difficulty**: Medium. The phrase is in the Discussion, where students may be less vigilant about genre. The shift from "theory explains findings" to "theory predicted findings" is subtle but important.

### TL-3: "We expected" framing for status differentiation finding
- **Location**: H3 subsection of Hypothesis Development
- **Exact text**: `We expected that AI adoption would create a new dimension of status differentiation based on AI fluency`
- **Type**: Temporal logic
- **Why it's a violation**: "We expected" implies the researcher entered the field anticipating this finding. Given that AI fluency as a status marker is a highly specific, context-dependent phenomenon, it is implausible that the researcher predicted it before beginning 14 months of ethnography. This is almost certainly a pattern that emerged from the data and was subsequently framed as an expectation.
- **Genre-appropriate alternative**: Remove the expectation claim entirely. In the findings, write: "An unexpected pattern emerged: AI fluency was becoming a new axis of status differentiation that crosscut the traditional experience-based hierarchy."
- **Difficulty**: Hard. "We expected" is softer than "we hypothesized" and some students may see it as acceptable. The violation is in the temporal claim, not just the word choice --- the student needs to ask "did the researcher really expect this before seeing data?"

---

## Summary Table

| ID | Location | Type | Exact Problematic Text | Difficulty |
|----|----------|------|----------------------|------------|
| SV-1 | Section header | Structural | "Theoretical Background and Hypothesis Development" | Easy |
| SV-2 | Theory subsections | Structural | H1, H2, H3 formal hypotheses | Easy |
| SV-3 | Results section | Structural | Results organized by hypothesis confirmation | Medium |
| SV-4 | Discussion/Future | Structural/Language | "variables and relationships we identified" | Hard |
| LV-1 | H1 Results | Language | "Consistent with our prediction" | Easy |
| LV-2 | H3 Results | Language | "As hypothesized" | Easy |
| LV-3 | H2 Results | Language | "We tested whether" | Medium |
| LV-4 | H2 Results | Language | "Results confirm the predicted migration" | Easy |
| LV-5 | H1 Results | Language | "Support for H1 was found" | Easy |
| TL-1 | Theory/Hypothesis Dev | Temporal logic | "Based on [theory], we predict..." | Medium |
| TL-2 | Discussion | Temporal logic | "As predicted by organizational learning theory" | Medium |
| TL-3 | H3 Hypothesis Dev | Temporal logic | "We expected that AI adoption would create..." | Hard |

---

## Distribution of Difficulty

- **Easy**: SV-1, SV-2, LV-1, LV-2, LV-4, LV-5 (6 violations)
- **Medium**: SV-3, LV-3, TL-1, TL-2 (4 violations)
- **Hard**: SV-4, TL-3 (2 violations)

A student who finds only the easy violations is demonstrating surface-level genre recognition (Level 1 competency). A student who also catches the medium violations is demonstrating applied genre analysis (Level 2). A student who catches the hard violations --- and can articulate WHY they're violations --- is demonstrating expert-level genre sensitivity (Level 3).

---

## Things That Are NOT Violations (Potential False Positives)

Students should NOT flag the following:

1. **The methods section describing iterative, grounded-theory-informed analysis.** This is actually genre-APPROPRIATE for a discovery paper. The methods section is one of the few places where the paper reads correctly.

2. **The use of direct quotes from informants.** Quotes are appropriate in both discovery and testing papers that use qualitative data. Their presence is not a genre issue.

3. **The discussion of boundary conditions.** Acknowledging limitations is appropriate in any genre. The Discussion section's boundary conditions paragraph is fine.

4. **The concept "human-AI assemblage."** This is a novel theoretical construct, which is exactly what discovery papers should produce. The problem isn't the concept --- it's that it's framed as if it were predicted rather than discovered.

5. **Citing organizational learning theory at all.** Discovery papers can and should use theory. The violation is in HOW the theory is used (as a source of predictions vs. as a sensemaking lens), not in the fact that theory is present.

6. **The abstract mentioning "contributions."** Stating contributions is standard in all genres. The problem with the abstract is the hypothesis language, not the contribution claims.

---

## Scoring Guidance

### Level 2 Assessment (Application with Feedback)

Using the rubric from ASSESSMENT_SPECS.md:

- **Detection (30 pts)**: Student should find at least 8 of 12 violations for full credit (violation_detection >= 0.67 for 20 pts, >= 0.80 for 30 pts)
- **Classification (15 pts)**: For each found violation, correctly classify as structural / language / temporal logic. 5 pts per correct classification, max 15.
- **Revision quality (30 pts)**: Holistic assessment of genre-appropriate rewrites.
- **Precision (10 pts)**: Penalize false positives --- flagging things that aren't broken.
- **Explanation quality (15 pts)**: Can the student articulate WHY each item is a violation?

### Level 3 Assessment (Authentic Performance)

Same rubric but no feedback during assessment. Student receives only the paper and instructions. Stricter floor: must score >= 20 on detection.

---

## Notes for Assessors

- The paper is intentionally competent in its substance. The observations are plausible, the quotes ring true, and the theoretical contribution (human-AI assemblages) is genuinely interesting. This is by design: students need to learn to distinguish framing problems from content problems.
- A common student error will be to flag the entire paper as "bad." It isn't bad --- it's good research badly framed. The assessment tests whether students can make this distinction.
- The methods section is the one place where the paper's genre is actually correct (iterative, grounded theory). Students who flag the methods section as problematic are demonstrating a misunderstanding.
- Some students may argue that the abstract is "the worst" violation. This is correct in the sense that the abstract concentrates multiple violation types, but each violation in the abstract should be scored separately per the rubric.
